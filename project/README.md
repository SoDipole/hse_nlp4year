# NLP project
### Группа: Лена Захарова, Денис Рахман, Настя Пискунова, Полина Сонина

* [Отчёт о планах](project_ideas.docx)

* Расширение списка:
  * [Блокнот с кодом для расширения списка (word2vec)](extend_seed_word2vec.ipynb)
  * [Расширенный список слов](w2v_all_clean.txt)
  * [Блокнот с кодом для поиска оценочных конструкций (RAKE)](extend_seed_with_rake.ipynb)
  * [Список конструкций](result_rake_multiword.txt)

* Коллокации:
  * [Блокнот с кодом для поиска коллокаций](find_collocations.ipynb)
  * [Список слов с коллокациями (топ 5 биграмм)](w2v_all_clean_collocations.json)

* Эмоциональная окраска:
  * [алгоритм, определяющий характер эмоциональной окраски лексемы (pos/neg/ambi)](https://github.com/SoDipole/hse_nlp4year/blob/master/project/emotions.py)
  * [результат его работы](https://github.com/SoDipole/hse_nlp4year/edit/master/project/results_polarity.txt)
* Отчет о проделанной работе:
Было использовано две модели word2vec: Одна с сайта RusVectores, обученная на википедии и НКРЯ, с большим словарём. Вторая - самостоятельно обученная на копусе твитов, собранном для sentiment-анализа. С помошью этих моделей были выделены слова, часто употребляющиеся в одном контексте с оценочными словами из seed. Как и предполагалось, эти лексемы в большинстве своем также оказались оценочными, что позволило значительно расширить seed.
Была произведена оценка тональности эмоционально окрашенных слов , выделенных в результате работы вышеописанного алгоритма. Для этого были лемматизированы корпус с положительными и корпус с отрицательными текстами твитов. После этого для каждого слова был определен некоторый коэффициент pos, выделенный на основании частотности этой лексемы в корпусе с положительными отзывами, и коэффициент neg, выделенный на основании частотности этой лексемы в корпусе с отрицательными отзывами. Разность этих значений и послужила основанием для определения тональности лексемы: отрицательные значения разности свидетельствуют об отрицательной тональности, а положительные -- о положительной. При этом чем больше модуль этой разности, тем, с одной стороны, слово является более эмоционально окрашенным, а с другой стороны, результат более достоверен. При значениях разности neg и pos близких к нулю, лексема помечалась как двусмысленная или недостаточно встречающаяся в корпусе. 
На тестовом множестве из 48 слов доля правильных решений алгоритма составила 62,5%. Однако, если убрать из рассмотрения слова, не встретившиеся в корпусах эмоционально окрашенных твитов ни разу,  доля правильных решений вырастает до 76%. Из этого можно сделать вывод, что основным фактором, понижающим качество работы алгоритма, является малый объем обучающих корпусов, и при его увеличении доля правильных решений должна существенно возрасти.
Кроме того, с помощью алгоритма RAKE были выделены словосочетания, с большой вероятностью являющиеся ключевыми для текстов из корпуса эмоционально окрашенных твитов. Как и предполагалось, такие словосочетания в большинстве своем также являются оценочными в силу специфики текстов.  В итоге было решено оставить в итоговом списке только те словосочетания, которые входят в 1000 наиболее частотных и содержат хотя бы одно слово из уже собранного нами списка однословной оценочной лексики.
Были выделены коллокации для расширенного с помощью word2vec списка ключевых слов. Был загружен и предобработан (лишен стоп-слов и токенизирован) корпус рецензий. Было принято решение отказаться от токенизации рецензий, так как это значительно увеличивало время работы алгоритма. На основании получившегося обработанного корпуса и выделялись коллокации, с помощью которых также были выделены топ 5 биграмм для слов из расширенного списка. 

