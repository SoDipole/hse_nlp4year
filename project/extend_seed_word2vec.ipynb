{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Расширение списка оценочных слов с помощью word2vec\n",
    "Идея - взять обученную модель word2vec, по очереди подавать в нее однословные элементы из seed, посмотреть на выдачу функции most_similar.\n",
    "Очень вероятно, что слова, употребляющиеся в сходных контекстах с оценочными словами из списка seed тоже будут оценочными. \n",
    "Используются две модели. Одна с сайта RusVectores, обученная на википедии и НКРЯ, с большим словарём. Вторая - самостоятельно обученная на копусе твитов, собранном для sentiment-анализа. Мы предполагаем, что эмоционально окрашенные тексты будут содержать больше оценочной лексики и результат получится более точным и полным. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from preprocessing import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('seed.txt') as file:\n",
    "    seed_tokens = [tokenize(line, need_pos = True) for line in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['аналог_NOUN', 'нет_PART'],\n",
       " ['подошва_NOUN'],\n",
       " ['вежливый_ADJ'],\n",
       " ['великолепный_ADJ'],\n",
       " ['вкусный_ADJ'],\n",
       " ['внимательный_ADJ'],\n",
       " ['большой_ADJ', 'выбор_NOUN'],\n",
       " ['вау_NOUN'],\n",
       " ['неплохой_ADJ'],\n",
       " ['идеальный_ADJ'],\n",
       " ['неприятный_ADJ'],\n",
       " ['понравиться_VERB'],\n",
       " ['рекомендовать_VERB'],\n",
       " ['ура_PART'],\n",
       " ['советовать_VERB'],\n",
       " ['отвратительный_ADJ'],\n",
       " ['отличный_ADJ'],\n",
       " ['положительный_ADJ'],\n",
       " ['отрицательный_ADJ'],\n",
       " ['приятный_ADJ'],\n",
       " ['напоминать_VERB', 'себя_PRON'],\n",
       " ['спасибо_NOUN'],\n",
       " ['радовать_VERB', 'глаз_NOUN'],\n",
       " ['совесть_NOUN'],\n",
       " ['молодец_NOUN'],\n",
       " ['прийти_VERB', 'еще_ADV', 'раз_NOUN'],\n",
       " ['орать_VERB'],\n",
       " ['улыбаться_VERB'],\n",
       " ['приветливый_ADJ'],\n",
       " ['отличный_ADJ'],\n",
       " ['замечательный_ADJ']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# оставляем только одиночные оценочные слова, + убираем \"подошву\" и \"орать\", \n",
    "# потому что основное значение этих слов не оценочное и они дадут много мусора\n",
    "good_seed_tokens = [\n",
    " ['вежливый_ADJ'],\n",
    " ['великолепный_ADJ'],\n",
    " ['вкусный_ADJ'],\n",
    " ['внимательный_ADJ'],\n",
    " ['вау_NOUN'],\n",
    " ['неплохой_ADJ'],\n",
    " ['идеальный_ADJ'],\n",
    " ['неприятный_ADJ'],\n",
    " ['понравиться_VERB'],\n",
    " ['рекомендовать_VERB'],\n",
    " ['ура_PART'],\n",
    " ['советовать_VERB'],\n",
    " ['отвратительный_ADJ'],\n",
    " ['отличный_ADJ'],\n",
    " ['положительный_ADJ'],\n",
    " ['отрицательный_ADJ'],\n",
    " ['приятный_ADJ'],\n",
    " ['спасибо_NOUN'],\n",
    " ['радовать_VERB'],\n",
    " ['молодец_NOUN'],\n",
    " ['улыбаться_VERB'],\n",
    " ['приветливый_ADJ'],\n",
    " ['отличный_ADJ'],\n",
    " ['замечательный_ADJ']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Готовая модель с rusvectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# предобученная модель с сайта RusVectores\n",
    "# 376 Мбайт, НКРЯ и  Википедия за декабрь 2017, размер копуса - 600 миллионов слов, размер словаря - 384 764,\n",
    "# частотный порог - 40 слов\n",
    "model = KeyedVectors.load_word2vec_format('ruwikiruscorpora_upos_skipgram_300_2_2018.vec.gz', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_similar_rv = []\n",
    "for token_set in good_seed_tokens:\n",
    "    if len(token_set) == 1:\n",
    "        try:\n",
    "            similar = model.most_similar(positive = token_set, negative = [], topn = 5)\n",
    "            all_similar_rv.extend([i[0].split('_')[0] for i in similar])\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_similar_rv = set(all_similar_rv)\n",
    "with open('w2v_rusvectores.txt', 'w') as file:\n",
    "    file.write('\\n'.join([i for i in all_similar_rv]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_similar_rv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель, обученная на корпусе твитов для sentiment-анализа "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('tweets.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_similar_tweets = []\n",
    "for token_set in good_seed_tokens:\n",
    "    if len(token_set) == 1:\n",
    "        token_set = [i.split('_')[0] for i in token_set]\n",
    "        try:\n",
    "            similar = model.most_similar(positive = token_set, negative = [], topn = 5)\n",
    "            all_similar_tweets.extend([i[0] for i in similar])\n",
    "        except:\n",
    "            print(token_set[0]+' not in vocabulary')\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_similar_tweets = set(all_similar_tweets)\n",
    "with open('w2v_tweets.txt', 'w') as file:\n",
    "    file.write('\\n'.join([i for i in all_similar_tweets]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_similar_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Интересно, что из выдачи двух моделей совпали только 7 слов\n",
    "len(all_similar_rv.intersection(all_similar_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('w2v_all.txt', 'w') as file:\n",
    "    file.write('\\n'.join([i for i in all_similar_rv.union(all_similar_tweets)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "+ В списке, составленном с помощью готовой модели 92 слова, из них действительно оценочных - 72.\n",
    "+ В списке, составленном с помощью готовой модели 107 слов, из них действительно оценочных - 63.\n",
    "+ Из выдачи двух моделей совпали только 7 слов, значит использование второй модели здесь было оправданным и она достаточно обогатила список. \n",
    "+ В итоговом чистом списке из обеих моделей (w2v_clean_all.txt) 128 слов.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
