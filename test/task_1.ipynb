{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### земля - планета / земля - вещество\n",
    "Любым способом выполните следующее задание (можно писать свой код, можно запускать готовый код, модифицировать код, который вы писали на курсе по машинному обучению, результат подавать на вход другому готовому коду или сравнивать с электронными лексикографическими ресурсами). \n",
    "Опишите всю цепочку вычислений. Задание. \n",
    "\n",
    "Соберите корпус, на котором можно обучаться для различения двух значений лексемы (лексему см. в табличке https://goo.gl/8YU1Dr) \n",
    "\n",
    "(NB: можно воспользоваться любым поисковиком, выдачей НКРЯ по специальным запросам - например, для датасета со словом ключ (см. датасет с семинарского занятия) я воспользовалась контекстами (-15--7 /+10 +15) \"вода|бить|лес...\" и т.п.; метод, которым вы создадите тренировочный корпус оценивается). \n",
    "\n",
    "Важно, чтобы метод создания датасета позволял рсставить значения автоматически, а не вручную.\n",
    "Датасет должен состоять примерно из 300 предложений. Составьте свой собственный тестовый сет из 8 предложений. \n",
    "\n",
    "Любыми двумя способами соберите признаки, на основе которых можно было бы различить два значения (PMI, Word2Vec, WordNet ...). \n",
    "Обучите классифкатор распознавать значения. \n",
    "\n",
    "Результат: топ 10 хороших признаков для различения значения 1 и значения 2; \n",
    "описание процедур, которые Вы применили или собирались применить для нахождения этих признаков (например, воспользовались word2vec - только укажите подробности, как именно); \n",
    "точность, полнота, F мера для кросс-валидации. \n",
    "Результат работы классификатора на Ваших 8 предложениях"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### создание корпуса\n",
    "- выбрала слова для коллокаций из ruSKELL\n",
    "    - для \"планеты\": планета|космос|орбита|космический|астероид|вращаться|марс|венера|спутник\n",
    "    - для \"вещества\": засыпать|присыпать|пахать|рыть|копать|песок|вода|сырой|дерновый|влажный|пложородный|горшок|закапывать|зарывать|выкапывать\n",
    "- поиск по контекстам (-10, +10) в НКРЯ\n",
    "\n",
    "взято: 150 с первым значением и 150 со вторым"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### программа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### загрузка стопслов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stop_words(stop_filename):\n",
    "    with open(stop_filename, encoding = 'utf-8') as f:\n",
    "        stopwords = [w.strip() for w in f.readlines() if w.strip()]\n",
    "    return set(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'после', 'даже', 'главный', 'рамка', 'по', 'едва', 'а', 'этот', 'ли', 'самый', 'восемь', 'не', 'лишь', 'что', 'уже', 'над', 'в', 'он', 'со', 'на', 'примечательно', 'первый', 'пока', 'ещё', 'два', 'по-прежнему', 'я', 'еще', 'она', 'каждый', 'с', 'без', 'и', 'здесь', 'стать', 'во', 'год', 'четыре', 'свой'}\n"
     ]
    }
   ],
   "source": [
    "stop_words = load_stop_words(\"stoplist_russian.txt\")\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### загрузка данных, препроцессинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(raw_text):\n",
    "    clean_text = re.sub('\\W+', ' ', raw_text) # \\W = [^a-zA-Z0-9_]\n",
    "    return clean_text\n",
    "\n",
    "def lemmatize(input):\n",
    "    return [lemma.strip() for lemma in m.lemmatize(preprocessing(input.lower())) if lemma.strip()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### обучающие данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Благодаря запуску на орбиту вокруг Земли специ...</td>\n",
       "      <td>планета</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Земля (орбита Земли) есть мера всех орбит.</td>\n",
       "      <td>планета</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Как видно из данного рисунка, между магнитными...</td>\n",
       "      <td>планета</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Сопоставление ВГП Солнца на поверхности планет...</td>\n",
       "      <td>планета</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Широтные параметры смещений, видимо, надо иска...</td>\n",
       "      <td>планета</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    sense\n",
       "0  Благодаря запуску на орбиту вокруг Земли специ...  планета\n",
       "1         Земля (орбита Земли) есть мера всех орбит.  планета\n",
       "2  Как видно из данного рисунка, между магнитными...  планета\n",
       "3  Сопоставление ВГП Солнца на поверхности планет...  планета\n",
       "4  Широтные параметры смещений, видимо, надо иска...  планета"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('earth_soil.csv', encoding='utf-8', sep = '\\t')\n",
    "df_train = df_train[['text', 'sense']]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>благодаря запуск орбита вокруг специализирован...</td>\n",
       "      <td>планета</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>орбита быть мера весь орбита</td>\n",
       "      <td>планета</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>как видно из данный рисунок между магнитный по...</td>\n",
       "      <td>планета</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>сопоставление вгп солнце поверхность планета и...</td>\n",
       "      <td>планета</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>широтный параметр смещение видимо надо искать ...</td>\n",
       "      <td>планета</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    sense\n",
       "0  благодаря запуск орбита вокруг специализирован...  планета\n",
       "1                       орбита быть мера весь орбита  планета\n",
       "2  как видно из данный рисунок между магнитный по...  планета\n",
       "3  сопоставление вгп солнце поверхность планета и...  планета\n",
       "4  широтный параметр смещение видимо надо искать ...  планета"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(df_train)):\n",
    "    processed_text = lemmatize(df_train.iloc[i][\"text\"])\n",
    "    processed_text_2 = []\n",
    "    for word in processed_text:\n",
    "        if (len(word) > 0 \n",
    "            and word not in stop_words \n",
    "            and word != \"земля\"):\n",
    "            processed_text_2.append(word)\n",
    "    df_train.iloc[i][\"text\"] = \" \".join(processed_text_2)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### тестовые данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В год столетия Сергея Павловича Королева, 150-...</td>\n",
       "      <td>планета</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>При этом оказывается, что центроид оболочки си...</td>\n",
       "      <td>планета</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Например, для Меркурия n = 10, для Венеры n =1...</td>\n",
       "      <td>планета</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Спутник плывет над сияющей Землей; колониальны...</td>\n",
       "      <td>планета</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Годится почвенная смесь, просеянная через мелк...</td>\n",
       "      <td>вещество</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     sense\n",
       "0  В год столетия Сергея Павловича Королева, 150-...   планета\n",
       "1  При этом оказывается, что центроид оболочки си...   планета\n",
       "2  Например, для Меркурия n = 10, для Венеры n =1...   планета\n",
       "3  Спутник плывет над сияющей Землей; колониальны...   планета\n",
       "4  Годится почвенная смесь, просеянная через мелк...  вещество"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('earth_soil_test.csv', encoding='utf-8', sep = '\\t')\n",
    "df_test = df_test[['text', 'sense']]\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>столетие сергей павлович королева 150 летие ко...</td>\n",
       "      <td>планета</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>при это оказываться центроид оболочка система ...</td>\n",
       "      <td>планета</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>например для меркурий n 10 для венера n 11 для...</td>\n",
       "      <td>планета</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>спутник плыть сиять колониальный народ бунтова...</td>\n",
       "      <td>планета</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>годиться почвенный смесь просеивать через мелк...</td>\n",
       "      <td>вещество</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     sense\n",
       "0  столетие сергей павлович королева 150 летие ко...   планета\n",
       "1  при это оказываться центроид оболочка система ...   планета\n",
       "2  например для меркурий n 10 для венера n 11 для...   планета\n",
       "3  спутник плыть сиять колониальный народ бунтова...   планета\n",
       "4  годиться почвенный смесь просеивать через мелк...  вещество"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(df_test)):\n",
    "    processed_text = lemmatize(df_test.iloc[i][\"text\"])\n",
    "    processed_text_2 = []\n",
    "    for word in processed_text:\n",
    "        if (len(word) > 0 \n",
    "            and word not in stop_words \n",
    "            and word != \"земля\"):\n",
    "            processed_text_2.append(word)\n",
    "    df_test.iloc[i][\"text\"] = \" \".join(processed_text_2)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### векторизация (tf-idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature matrix shape (300, 11961)\n"
     ]
    }
   ],
   "source": [
    "#vec = TfidfVectorizer(analyzer='char', ngram_range=(1,8), norm=None, use_idf=False, binary=True, max_df = 600)\n",
    "vec = TfidfVectorizer(analyzer='word', ngram_range=(1,3), use_idf=True, binary=True, norm='l2')\n",
    "X = vec.fit_transform(df_train.text)\n",
    "print('feature matrix shape', X.shape)\n",
    "\n",
    "# encode class labels\n",
    "label_enc = LabelEncoder().fit(df_train.sense)\n",
    "y_train = label_enc.transform(df_train.sense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### обучение модели (баесовский классификатор)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit our prediction model\n",
    "model = MultinomialNB(alpha=1.0)\n",
    "model.fit(X, y_train)\n",
    "\n",
    "# perfomance on test dataset\n",
    "X_test = vec.transform(df_test.text)\n",
    "y_pred = model.predict(X_test)\n",
    "y_test = label_enc.transform(df_test.sense)\n",
    "X_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## кросс-валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision 0.969485294118\n",
      "recall 0.986666666667\n",
      "f1 0.977176028921\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print ('precision', np.mean(cross_val_score(model, X, y_train, cv=10, scoring='precision')))\n",
    "print ('recall', np.mean(cross_val_score(model, X, y_train, cv=10, scoring='recall')))\n",
    "print ('f1', np.mean(cross_val_score(model, X, y_train, cv=10, scoring='f1')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## результат на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "print('accuracy', metrics.accuracy_score(y_test, X_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "настоящие значения [1 1 1 1 0 0 0 0]\n",
      "предсказания модели [1 1 1 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"настоящие значения\", y_test)\n",
    "print(\"предсказания модели\", X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
